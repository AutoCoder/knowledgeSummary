# 概论

统计学习方法有三部分组成 ： 模型 + 策略 + 算法

#### **模型**

它是学习的目标，一般为决策函数 $$Y=f(x)$$ 或者条件概率分布 $$P(Y|X)$$

模型的假设空间，包含所有可能的决策函数或者条件概率分布：

$$F = \{ f | Y = f_{\theta }(X), \theta \in R^{n} \}$$	

模型的学习目的就是在假设空间中寻找最优的$$\theta$$

**模型分类**：

- 判别模型     $$Y = f(x)$$ 或者 $$Y = P(Y|X)$$ 如逻辑回归 knn 感知机 决策树 最大熵 SVM boosting CRF

- 生成模型     统计出 $$P(X,Y)$$ , 然后得出     $$ \displaystyle P(Y|X) =  \frac{P(X,Y)}{P(X)}$$ 如朴素贝叶斯和隐式马尔科夫

**模型评价**：

预测分为对和错两种情况{ True(**T**),  False(**F**) }，类别分为正负两种情况 {Positive(**P**),  Negative(**N**) }
	
于是预测就出现了四种状态 {**TP**, **TN**, **FP**, **FN**}
	
正确率 ： $$\displaystyle \frac{TP}{TP + FP}$$
	
召回率 ： $$\displaystyle\frac{TP}{TP + FN}$$
	
F1(正确率和召回率的调和平均数) : $$1/F1 = (1/Precison + 1/Recall) * 1/2 $$

AUC： 一个正样本排在负样本之前的概率（ROC 曲线下的面积）

ROC的横轴是假正类率(FP/TN+FP) 纵轴是真正类率(TP/TP+FN)，随着threshold 曲线发生变化

------

#### 策略

它决定了以什么标准来寻找最优的决策函数和条件概率分布，比如选择怎么样的**损失函数**和**风险函数**。

- **损失函数**：$$L ( Y, f(X))$$ ，它用来评价一次预测的好坏

  常见的损失函数(损失越小越好)：

  0-1损失函数： $$L ( Y, f(X)) = \left\{\begin{matrix} 1, Y \neq f(X) \\ 0, Y = f(X) \end{matrix}\right.$$

  平方损失函数 : $$L ( Y, f(X)) = ( Y - f(X))^{2}$$

  绝对损失函数 :  $$L ( Y, f(X)) = | Y - f(X) |$$

  对数损失函数 :  $$L ( Y, f(X)) = - logP(Y|X) $$

  【理解】： 目标所有样本的联合概率最大 $$\displaystyle max \prod_{i=0}^{m} P(Y|X) \Rightarrow min \prod_{i=0}^{m}\frac{1}{P(Y|X)}  $$

  		     所以损失函数取对数：$$log \frac{1}{P(Y|X)} \Rightarrow -logP(Y|X)$$

- **风险函数** :  一般用于评价平均意义下的好坏，也叫做期望损失，是随机变量$$(X,Y)$$ 在$$f_{\theta }(x)$$模型下的损失函数的期望：

  $$R_{exp}(f) = E_{p}[L(Y, f(x))] = \int_{x,y}L(Y, f(x)) P(x,y)dxdy$$                                             (x，y连续分布的情况)

  $$R_{exp}(f) = E_{p}[L(Y, f(x))] = \frac{1}{n} \sum_{i=0}^{n}L(Y, f(x))$$                                                            (x，y离散分布的情况)

  给定一个训练集    $$T = \{ (x_{1},y_{1}),(x_{2},y_{2})...(x_{n},y_{n}) \}$$ 那么经验损失为 $$R_{emp} (f) = \frac{1}{n} \sum_{i=0}^{n}L(Y^{(i)}, f(x^{(i)}))$$     

   当n趋向无穷大时，经验损失无限接近期望损失, 但是当n较小时（现实世界中往往就是这样），经验风险最小过产生过拟合，经验损失不能近似期望损失，这之后就需要引入**结构风险最小化**.

- **结构风险**

  $$R_{srm} (f) = \frac{1}{n} \sum_{i=0}^{n}L(Y^{(i)}, f(x^{(i)})) + \lambda J(f)$$, $$J(f)$$ 为模型的复杂度，也叫做模型复杂度的惩罚项

------

#### 算法

学习模型的具体计算方法，比如梯度下降法。 选择不同的算法，用于达到找到全局最优解，加快迭代速度的目的。