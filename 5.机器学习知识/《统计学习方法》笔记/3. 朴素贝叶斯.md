# 朴素贝叶斯

重要假设 =》 每个特征都是独立的($$X^{(1)},...X^{(n)}$$是X的n个特征分量), 即：

$$\displaystyle P(X=x|Y = c_{k}) = P(X^{(1)} = x^{(1)}, ... X^{(n)} = x^{(n)} | Y = c_{k}) = \prod_{j=1}^{n}P(X^{(j)} = x^{(j)}|Y = c_{k})$$

对于给定的训练集，学习输入X和输出Y的联合概率分布， 然后基于此模型，对于新输入x，利用贝叶斯定理求出后验概率最大的y。

$$\displaystyle P(y|x) = \frac{p(x|y) * p(y)}{p(x)}$$, P(y|x) 是后验概率，即我们的求解目标，

p(x|y) 是条件概率，又叫似然概率，p(x),p(y)都是先验概率。

【例子】: y是天气情况，是一个枚举值{晴天，阴天，雨天}；x是一个观测特征 - 前一天湿度值{$$\lt80\%$$, $$\geq 80\%$$ }。已知当天湿度x, 预测明天的天气y， 即求解p(y|x)。 已经在拥有训练集的情况下， p(x), p(y), p(x|y) 这些可以在训练集上统计出来。



**拉普拉斯平滑** (Laplace Smoothing)

假设在文本分类中，有3个类，C1、C2、C3，在指定的1000个训练样本中，某个词语K1，在各个类中观测计数分别为0，990，10，K1的概率为0，0.99，0.01，对这三个量使用拉普拉斯平滑的计算方法如下：
1/1003 = 0.001，991/1003=0.988，11/1003=0.011

分子+1，分母+3（分类取值范围）

