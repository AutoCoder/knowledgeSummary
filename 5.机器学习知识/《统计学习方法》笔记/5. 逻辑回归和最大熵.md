# 逻辑回归和最大熵

最大熵是模型学习的一个准则，将其推广到分类问题，得到最大熵模型。逻辑回归和最大熵都是对数线性模型。



### 最大熵

假定有数量为N的训练集$$ \{(x_{1},y_{1}), (x_{2},y_{2}),...(x_{N},y_{N})\}​$$

经验联合分布 $$\displaystyle  \tilde{P}(X = x, Y = y) = \frac {v (X = x, Y = y) } {N}$$

经验边缘分布 $$\displaystyle  \tilde{P}(X = x) = \frac {v (X = x) } {N}$$

特征二值函数$$ f(x,y) $$描述$$x,y $$之间是否满足一个事实: 

$$f(x,y) = \left\{\begin{matrix}1, \quad (x,y)\ meet\ one\ fact \\0,  \quad  otherwise \end{matrix}\right.$$

用$$E_{\tilde{p}}(f)$$表示f(x,y) 关于经验分布 $$\tilde{P}(x,y)$$的期望  $$\displaystyle E_{\tilde{p}} = \sum_{x,y} \tilde{P}(x,y) f(x,y)$$

用$$E_{p}(f)$$表示f(x,y) 关于模型$$P(Y|X)$$ 和经验分布 $$\tilde{P}(x)$$的期望  $$\displaystyle E_{p} = \sum_{x,y} \tilde{P}(x)P(y|x) f(x,y)$$

如果模型$$P(Y|X)$$ 和训练数据 同分布，那么 $$\displaystyle E_{\tilde{p}}(f) =  E_{p}(f)$$ 即 $$\displaystyle\sum_{x,y} \tilde{P}(x,y) f(x,y) = \sum_{x,y} \tilde{P}(x)P(y|x) f(x,y)$$

假设有n个特征函数，那么就有n个这种约束。



条件熵 $$H(Y|X) = - \sum _{x,y} \tilde{P}(x) P(y|x) log P(y|x) $$

满足约束的情况下，使得条件熵最大，即是最大熵模型：

那么该模型转化为如下优化问题：

$$\displaystyle \max_{p(y|x)}\ \  H(Y|X) \ \ \ \ \Rightarrow \ \ \ \  \min_{p(y|x)} -H(Y|X) $$

$$s.t. \ \ E_{\tilde{p}}(f) =  E_{p}(f)$$

$$\displaystyle s.t. \sum_{y} p(y|x) = 1$$

转换成拉格朗日函数 $$\displaystyle L(P, w) = \sum _{x,y} \tilde{P}(x) P(y|x) log P(y|x)  + w_{0} (1 - \sum_{y} p(y|x))$$

$$\displaystyle + w_{1} (\sum_{x,y} \tilde{P}(x,y) f(x,y) - \sum_{x,y} \tilde{P}(x)P(y|x) f(x,y))$$

原始问题 :  $$\displaystyle \min_{P} \max_{w}L(P, w)$$

对偶问题： $$\displaystyle \max_{w} \min_{P} L(P, w)$$

由于拉格朗日函数$$L(P, w) ​$$ 是凸函数，原始问题等价于对偶问题

对偶函数 :$$ \displaystyle \Psi (w) =  \min_{P} L(P, w)$$

先求解 $$\displaystyle \min_{P} L(P, w)$$, 令 $$\displaystyle \frac{\partial L(P, w)}{\partial P(y|x)} = 0$$ , 得到 $$P_{w}$$

之后求解 $$\displaystyle  \max_{w}\Psi (w) $$, 得到 $$\displaystyle w^{*} = arg\max_{w}\Psi (w)$$

求解后，最大熵模型可以写成如下一般化公式：

$$\displaystyle P_{w}(y|x) = \frac{exp(\sum_{i}w_{i}f_{i}(x,y)) }{ Z_{w}(x) }$$

归一化因子 $$\displaystyle Z_{w}(x)  = \sum_{y}(exp(\sum_{i}w_{i}f_{i}(x,y))) $$

