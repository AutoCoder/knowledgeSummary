**1 . 有哪些特征选择的方法?** 

1. Filter
  * 方差选择法 （选择方差大于阈值的特征，因为方差越接近0，越说明这个特征是常数，不产生影响）

  * 相关系数法  （pearson相关系数法）

      方差 :       $$\displaystyle \sigma ^{2} = \frac{\sum_{i=0}^{n}(X_{i}-Mean)^{2}}{n}$$

      协方差：$$ \displaystyle cov(X,Y) =  \frac{\sum_{i=0}^{n}(X - \mu_{X})(Y - \mu_{Y})}{n}$$

      皮尔逊系数：$$\displaystyle \rho (X, Y) = \frac{cov(X,Y)}{\sigma _{X}\sigma _{Y}} = \frac{E[(X - \mu_{X})(Y - \mu_{Y})]}{\sigma _{X}\sigma _{Y}}  = \frac{\sum_{i=0}^{m}(x_{i} - \mu_{x})(y_{i} - \mu_{y})}{\sqrt{\sum_{i=0}^{m}(x_{i} - \mu_{x})^{2}}\sqrt{\sum_{i=0}^{m}(y_{i} - \mu_{y})^{2}}}$$

  * 卡方检验

  * 互信息法

      $$I(X, Y) = I(X) - H(X|Y)$$

      与输出Y互信息越大，说明这个特征越重要

      ![img](https://pic4.zhimg.com/80/v2-28ed43b6ebb16c5b5d995d4d06407f2c_hd.jpg) 
2. Wrapper

     +	递归特征消除法 （每次使用LR做特征权重排序）

3. Embedded
     + 基于惩罚项的特征选择法

         L1正则化，会是LR得到稀疏解，从而筛除特征

     + 基于树模型的特征选择法

         树模型中GBDT也可用来作为基模型进行特征选择，GBDT (Gradient boosting decision tree) 会返回每个子tree的权重。




##### 2. 处理哪些问题时需要对数据进行标准化？

- 分类（如k-nearest neighbors算法）

- 聚类（如k-means算法）

  使用距离（如欧几里得距离）来判定样本之间的相似度的分类和聚类问题，都要进行数据规范化。

- 支持向量机SVM（support vector machine），逻辑回归logistic regression, perceptron, neural networks etc.

  上面这些问题使用梯度优化来获得最优解。比如支持向量机使用梯度优化得到将样本数据分开的最优超平面。

- 主成分分析（principal component analysis）, linear discriminant analysis, kernel principal component analysis

  

  **总之，涉及到距离、协方差（比如PCA本质涉及协方差计算）、梯度计算的问题要进行标准化。**

  **距离、协方差，是因为要使各特征贡献一致所以使用标准化**

  **梯度计算，是因为如果不标准化，模型的收敛会很慢或者不会收敛到最优解。**



3. ##### 信噪比低的特征是否应该加入到模型中去？

   	实际误差=训练集误差+f(模型复杂度)

   为什么会这样呢？因为随着模型复杂程度的提高（例如在线性回归中加入越来越多的参数）模型会更倾向于较好的拟合训练数据。这是统计学习模型的基本性质之一[1](http://blog.codinglabs.org/articles/accurately-measuring-model-prediction-error.html#ref1)。在我们的幸福指数预测模型中，如果我们将人的姓氏也当做一个特征，那么训练数据的误差相比之前就会下降。如果我们将一个已破产公司在1990年1月1日不同时段的股票价格作为特征加入，训练集误差也会下降。甚至我们通过掷骰子随机生成一列数据作为特征加入也可以降低训练集误差。无论增加的特征列与模型有没有关系，训练集误差总会随着特征的增加而下降。

   同时，随着模型复杂度的增加，实际误差也会随之变化（我们实际关心的）。如果我们在幸福指数预测模型中加入了一个公司上世纪某一天的股票价格波动，那么可以预计模型的实际质量将降低。虽然股票价格可以降低训练集误差，但同时拉高了模型对于新数据的预测误差，因为加入股票价格特征后模型的稳定性变差了，因此在新数据上的预测表现随之下降。**甚至就算你加入了一个与模型相关的预测变量，如果这个变量的信噪比较低，模型的实际误差依然会变大**。

   [相关链接](http://blog.codinglabs.org/articles/accurately-measuring-model-prediction-error.html)

