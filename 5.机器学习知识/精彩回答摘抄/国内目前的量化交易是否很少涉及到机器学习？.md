作者：TraderJay's

链接：https://www.zhihu.com/question/47913794/answer/120067139

来源：知乎

著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

在我看来， ML用于金融数据最大的问题是信噪比太低，“同分布”的数据量太少。 其他领域ml效果好的往往都有比较确定的模式， 只是模式很难规则化而已。 比如人脸识别， 虽然很难通过规则话程序语言描述人脸，但100个普通人来识别人脸，错误率非常低。说明这里是有一个规律性pattern的。这样的话，只要给出足够数量的数据，模型性能会显著提高。另外一个例子是智能驾驶，你并
不需要if else编程遍历到所有可能情况，只需要让传感器采集到足够长时间多地域的数据，自动驾驶能够很好的处理这些情况。 以上的例子从数据角度来说，都符合pattern相对固定，数据充足的，信噪比高的特征。这也是ML方法最适合的地方。

 而即使是这样，在做预测的时候也需要主动选取特征，feature engineering也是一门巨大的学问。有人也许会说最近很火的cnn/deep learning, 不是可以by pass feature engineering这些，直接靠数据和计算力暴力撸么。 我是这样理解的， 人类识别特征和模式的能力远高于计算机， 如果需要让计算机逼近取代人的调参和feature engineering经验，那么你所需要的数据量是非线性增长的。很多通常运用ML的场所，数据量本身不是制约，或说，数据量的制约取决于你有多大的决心去获取数据。而机器运算能力的同步增长让更是让模型能够处理的数据大大提升。在这种情况下，deep learning才火起来。

然而金融世界里，事情并没有这么美好，最大的制约，在我看来数据是不足的。有人可能会笑，说tick level data，哪怕国内3秒一跳的股市也有4000多行一天，怎么能算是数据不足呢。
这里假设也用之前开车的例子来解释。金融世界里，如果你想训练出这么一个老司机，那么你会发现这辆车一会在人行道上， 一会倒开，一会儿飞起来， 前一刻有用的规律不一定能够稳定到下一刻。 又好比给一张股票k线图，100个人可能有100个说法， 语音识别，图像识别领域，不会出现这么低的识别度的。 所以，对一个正常开车的老司机，你坐副驾驶一个月能够总结出他开车方法，那么对于金融世界里这种逗逼老司机，又要积累多长时间的数据才能总结出它的行为模式呢。

也就是说金融时间序列里，训练集发现的pattern可能并不稳定， 也许只是过拟合的噪音， 哪怕确定不是噪音，pattern本身也会演化。这两个月的市场，和前两个月的市场，明显性状不一样。有个东东叫regime switch...哪怕你做的日内中高频，相对统计性状不受基本面太大影响，日度的波动率的变化也会有明显的变化，而这对你的pnl影响是非常直接的。

目前为止，在金融数据这块我个人还是偏好线性的描述，规则化的描述，因为这样即使错了，我知道错误在哪里，利润来源在哪里。 哪怕需要更复杂的信号组合，我也偏向random forest 或者svm 这种相对不那么容易过拟合的模型. 当然，这只是我个人的看法, 如果有其他的思路，也欢迎指出。