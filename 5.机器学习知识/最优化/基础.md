# 最优化

任意一个带约束的优化问题都可以表达成：

$$min\  \ f_{0}(x)$$

$$s.t. \  \  f_{i}(x) \leq 0, i = 1,2..., m$$

$$\ \ \ \ \ \ \ \ \ h_{i}(x) = 0, i = 1,2..., p$$

如果$$ f_{0}(x)... f_{m}(x) $$都是[凸函数](#convexfunc)， 且$$ h_{0}(x)... h_{p}(x) $$都是仿射函数(形式为 $$Ax+ b$$ )，那么这个问题就叫做**凸优化**。

凸函数： 凸函数是一个定义在某个向量空间的凸子集C（区间）上的实值函数f，而且对于凸子集C中任意两个向量, $$f((x1+x2)/2)>=(f(x1)+f(x2))/2$$,则$$f(x)$$是定义在凸子集C中的凸函数。

**拉格朗日函数** ： $$\displaystyle L(X, \lambda, \nu) = f_{0}(x) + \sum_{i=1}^{m} \lambda _ {i} f_{i}(x) +  \sum_{i=1}^{p} \nu _ {i} h_{i}(x) $$ 将有约束转换成无约束的最优化问题

令 $$\displaystyle Z(x) = \max_{\lambda \gt 0, \nu} L(X, \lambda, \nu)$$

如果$$X^{*}$$满足约束，那么 $$L(X, \lambda, \nu) \leq f_{0}(x),\  \ Z(x) =  f_{0}(x)$$ 那么之前的带约束的问题，就转化成了 

$$\displaystyle min f_{0}(x)  = min Z(x)  = min  \max_{\lambda \gt 0, \nu} L(X, \lambda, \nu)$$



**对偶问题**

感性理解： 胖子群里面的最瘦的那个，比瘦子群里最胖的那个胖

**拉格朗日对偶函数**： 记为 $$\displaystyle g( \lambda, \nu) = \min_{x} L(X, \lambda, \nu)$$

$$g( \lambda, \nu)$$ 为原始拉格朗日函数的下界。

假设原始问题在$$X^{*} 取得极值 $$ $$\rho^{*}$$， 那么

$$\displaystyle g( \lambda, \nu) = \min_{x} L(X, \lambda, \nu)  \leq  L(X^{*}, \lambda, \nu) \leq f_{0}(x^{*}) $$

那么$$ \displaystyle \max_{\lambda \gt 0, \nu} g( \lambda, \nu) $$ 就是最大的下届 $$d^{*}$$， $$d^{*} \leq \rho^{*}$$ 这叫做弱对偶性，对任何优化问题都适用。

$$duality\ gap  = \rho^{*} - d^{*}$$, 如果对偶间隔为0 ，则叫做**强对偶性**， 对偶问题的解就是原始问题的解。

**为什么需要对偶问题？**

需要注意的是，无论原始是什么形式，对偶问题总是一个凸优化问题——它的极值是唯一的（如果存在的话），并且有现成的软件包可以对凸优化问题进行求解。 这样一来，对于那些难以求解的原始问题（比如，甚至可以是 NP 问题），我们可以通过找出它的对偶问题 ，通过优化这个对偶问题来得到原始问题的一个下界估计。或者说我们甚至都不用去优化这个对偶问题 ，而是（通过某些方法，例如随机）选取一些 λ⪰0 和 ν ，带到 g(λ,ν) 中，这样也会得到一些下界（只不过不一定是最大的那个下界而已）。当然要选 λ 和 ν 也并不是总是“随机选”那么容易，根据具体问题，有时候选出来的 λ 和 ν 带入 g 会得到 −∞ ，这虽然是一个完全合法的下界，然而却并没有给我们带来任何有用的信息。

SVM假定了强对偶性。

假设$$ x^{*} $$和$$ ( \lambda^{*}, \nu^{*}) $$分别是原始无约束函数Z(x) 和 对偶函数 $$g( \lambda, \nu)$$的极值点，相应的极值为 $$\rho^{*}$$ 和 $$d^{*} $$，首先 $$\rho^{*} = d^{*} $$，此时我们可以得到 :

​          $$f_{0}(x^{*}) = g( \lambda^{*}, \nu^{*})$$

​		     $$\displaystyle = \min_{x}(f_{0}(x^{*}) + \sum_{i=1}^{m}\lambda_{i}^{*}f_{i}(x^{*}) + \sum_{i=1}^{p}\nu_{i}^{*}h_{i}(x^{*}))$$

​		     $$ \displaystyle \leq  f_{0}(x^{*}) + \sum_{i=1}^{m}\lambda_{i}^{*}f_{i}(x^{*}) + \sum_{i=1}^{p}\nu_{i}^{*}h_{i}(x^{*})$$	

​		     $$\leq f_{0}(x^{*})$$

推出    $$ \lambda_{i}^{*}f_{i}(x^{*}) = 0 , \ \  i = 1, 2, ..., m$$

所以KKT条件为：

​           $$ \lambda_{i}^{*}f_{i}(x^{*}) = 0 , \ \  i = 1, 2, ..., m$$

​	   $$ \lambda_{i}^{*} \geq 0 $$

​           $$\displaystyle \bigtriangledown f_{0}(x^{*}) + \sum_{i=1}^{m}\lambda_{i}^{*}\bigtriangledown f_{i}(x^{*}) + \sum_{i=1}^{p}\nu _{i}^{*}\bigtriangledown h_{i}(x^{*}) = 0$$

------

【对偶问题例子】

线性规划中一个经典问题的描述如下：　　  

某工厂有两种原料A、B，而且能用其生产两种产品： 1、生产第一种产品需要2个A和4个B，能够获利6；  2、生产第二种产品需要3个A和2个B，能够获利4； 此时共有100个A和120个B，问该工厂最多获利多少？ 用数学表达式描述如下： 

 $$\max \ \   6x_{1}+4x_{2}$$

 $$s.t. \ \ \   2x_{1}+3x_{2}≤100$$

$$s.t. \ \ \   2x_{1}+3x_{2}≤100$$

工厂除了拿原料生产成产品卖掉这条出路外，还有一种方法是直接将原料卖掉。当然，不管是怎么做都要利益越大话！也就是说，把原料卖掉赚的钱比生产成产品赚的钱多，才去会这样做。那么最低可以接受多少的价格呢？假设资源A和B的单价分别为：$$w_{1}$$和$$w_{2}$$，那么可以用数学表达式描述如下：  

$$\min\ \ \    100w1+120w2$$  

$$s.t.\ \ \     2w_{1}+4w_{2}≥6$$

$$s.t.\ \ \   3w_{1}+2w{2}≥4$$

 这两个问题互为对偶问题,分别称之为原问题P和对偶问题D。



[目前阐述最清楚的博文](http://blog.pluskid.org/?p=702) 