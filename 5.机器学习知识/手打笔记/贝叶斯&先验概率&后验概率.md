**贝叶斯公式** ：$$\displaystyle p(\theta|x)= \frac{p(x|\theta) * p(\theta)}{p(x)}\tag{1}$$

观察到的结果 $$x$$

决定分布的参数 $$\theta$$

后验概率 $$p(\theta|x)$$   $ posterior$

先验概率 $$p(\theta)$$      $ prior$

似然概率 $$p(x|\theta)$$   $likelihood$

例子：

> 作者：Agenter
>
> 链接：https://www.zhihu.com/question/24261751/answer/158547500
>
> 来源：知乎
>
> 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
>
> 隔壁老王要去10公里外的一个地方办事，他可以选择走路，骑自行车或者开车，并花费了一定时间到达目的地。在这个事件中，可以把交通方式（走路、骑车或开车）认为是原因，花费的时间认为是结果。
>
> 若老王花了一个小时的时间完成了10公里的距离，那么很大可能是骑车过去的，当然也有较小可能老王是个健身达人跑步过去的，或者开车过去但是堵车很严重。若老王一共用了两个小时的时间完成了10公里的距离，那么很有可能他是走路过去的。若老王只用了二十分钟，那么很有可能是开车。这种先知道结果，然后由结果估计原因的概率分布，*p*(交通方式|时间)，就是后验概率。
>
> 老王早上起床的时候觉得精神不错，想锻炼下身体，决定跑步过去；也可能老王想做个文艺青年试试最近流行的共享单车，决定骑车过去；也可能老王想炫个富，决定开车过去。老王的选择与到达目的地的时间无关。先于结果，确定原因的概率分布，*p*(交通方式)，就是先验概率。
>
> 老王决定步行过去，那么很大可能10公里的距离大约需要两个小时；较小可能是老王平时坚持锻炼，跑步过去用了一个小时；更小可能是老王是个猛人，40分钟就到了。老王决定骑车过去，很可能一个小时就能到；较小可能是老王那天精神不错加上单双号限行交通很通畅，40分钟就到了；还有一种较小可能是老王运气很差，连着坏了好几辆共享单车，花了一个半小时才到。老王决定开车过去，很大可能是20分钟就到了，较小可能是那天堵车很严重，磨磨唧唧花了一个小时才到。这种先确定原因，根据原因来估计结果的概率分布，*p*(时间|交通方式)，就是似然估计。
>
> 老王去那个地方好几趟，不管是什么交通方式，得到了一组关于时间的概率分布。这种不考虑原因，只看结果的概率分布，*p*(时间)，也有一个名词：evidence（不清楚合适的中文名是什么）

根据这个例子，交通方式是$$\theta$$, 时间为$x$,  我们常常面对的问题就是通过观察到的$x$ 来推测交通方式$$\theta$$（也就是常常说的分布）



**MLE最大似然概率 vs MAP最大后验概率** 

- 频率学派 - Frequentist - Maximum Likelihood Estimation (MLE，最大似然估计)
- 贝叶斯学派 - Bayesian - Maximum A Posteriori (MAP，最大后验估计)

> 抽象一点来讲，频率学派和贝叶斯学派对世界的认知有本质不同：频率学派认为世界是确定的，有一个本体，这个本体的真值是不变的，我们的目标就是要找到这个真值或真值所在的范围；而贝叶斯学派认为世界是不确定的，人们对世界先有一个预判，而后通过观测数据对这个预判做调整，我们的目标是要找到最优的描述这个世界的概率分布
>
> **(1) 频率学派：**存在唯一真值 $$\theta$$  。举一个简单直观的例子--抛硬币，我们用$p(Head)$ 来表示硬币的bias。抛一枚硬币100次，有20次正面朝上，要估计抛硬币正面朝上的bias $p(Head)$。在频率学派来看，$\theta = 20/100 =0.2$，很直观。当数据量趋于无穷时，这种方法能给出精准的估计；然而缺乏数据时则可能产0生严重的偏差。例如，对于一枚均匀硬币，即 $\theta=0.5$，抛掷5次，出现5次正面 (这种情况出现的概率是1/2^5=3.125%)，频率学派会直接估计这枚硬币 $\theta$ = 1，出现严重错误。
>
> **(2) 贝叶斯学派：** ![\theta](https://www.zhihu.com/equation?tex=%5Ctheta) 是一个随机变量，符合一定的概率分布。在贝叶斯学派里有两大输入和一大输出，输入是先验 (prior)和似然 (likelihood)，输出是后验 (posterior)。*先验*，即 $P(\theta)$ ，指的是在没有观测到任何数据时对 $\theta$ 的预先判断，例如给我一个硬币，一种可行的先验是认为这个硬币有很大的概率是均匀的，有较小的概率是是不均匀的；*似然*，即 $P(x|\theta)$ ，是假设 $\theta$已知后我们观察到的数据应该是什么样子的；*后验*，即 $P(\theta|x)$ ，是最终的参数分布。贝叶斯估计的基础是贝叶斯公式

**MLE**最大似然估计 是频率学派最常用的估计方法:

假设$$X= (x_{1}, x_{2}, x_{3},... x_{n})$$ 为数据的一组独立同分布的抽样，那么对$\theta$的最大似然估计可以记为$\hat{\theta}_{MLE}$

$$\hat{\theta}_{MLE} = argmax\ p(X;\theta)$$

$$= argmax(p(x_{1};\theta)p(x_{2};\theta)...p(x_{n};\theta))$$

$$\displaystyle=argmax\ log\prod_{i=1}^{n}p(x_{i};\theta)$$

$$\displaystyle=argmax\ \sum_{i=1}^{n} log(p(x_{i};\theta))$$

$$\displaystyle= argmin\ -\sum_{i=1}^{n} log(p(x_{i};\theta))$$

深度学习做分类任务时所用的cross entropy loss 其本质也是MLE（还不知道为啥）



**MAP** 最大后验估计，是贝叶斯学派常用的估计方法:

$$ \hat{\theta}_{MAP} = argmax\ p(\theta|X) $$

$$= argmax\ log(p(\theta|X))$$

$$= argmax\ log(\frac{p(X|\theta) * p(\theta)}{p(X)})$$

$$ = argmax\ log(p(X|\theta)) + log(p(\theta)) - log(p(X))$$

$$= argmax\ log(p(X|\theta)) + log(p(\theta))$$                                  # logp(X) 与 $\theta$无关了

$$= argmin - log(p(X|\theta)) - log(p(\theta))$$

**所以MLE和MAP在优化时的不同就是在于先验项** $log(p(\theta))$

高斯分布密度函数 $$f(x) = \frac{1}{\sqrt{2\pi}\sigma} exp(- \frac{(x-\mu)^2}{2 \sigma^2})$$   假设 $\theta$ 服从 $N(0, \sigma)$ 分布，那么

如果$\theta$ 假定符合高斯分布 $$logp(\theta) = log(constant * e ^ { -\frac{\theta^{2}} {2 \sigma^{2}}}) =   C||\theta||^2$$ 

那么 $$ -log(p(\theta)) = C_1+  C_2||\theta||^2$$  , 所以在后验估计中使用高斯先验分布，那么等于 MLE + L2

拉普拉斯密度函数   $$f(x|\mu,b) = \frac{1}{2b} exp(- \frac{|x-\mu|}{b})$$， 假设 $\theta$ 服从 $La(0, b)$ 分布，那么

那么 $$ -log(p(\theta)) = C_1+  C_2||\theta||$$ , 那么等于 MLE + L1

