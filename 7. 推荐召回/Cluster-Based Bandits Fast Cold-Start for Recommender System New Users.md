ABSTRACT
How to quickly and reliably learn the preferences of new users remains a key challenge in the design of recommender systems. In
this paper we introduce a new type of online learning algorithm, cluster-based bandits, to address this challenge. This exploits the
fact that users can often be grouped into clusters based on the similarity of their preferences, and this allows accelerated learning of
new user preferences since the task becomes one of identifying which cluster a user belongs to and typically there are far fewer
clusters than there are items to be rated. Clustering by itself is not enough however. Intra-cluster variability between users can
be thought of as adding noise to user ratings. Deterministic methods such as decision-trees perform poorly in the presence of such
noise. We identify so-called distinguisher items that are particularly informative for deciding which cluster a new user belongs to
despite the rating noise. Using these items the cluster-based bandit algorithm is able to efficiently adapt to user responses and rapidly
learn the correct cluster to assign to a new user.

å¦‚ä½•å¿«é€Ÿå¯é çš„å­¦ä¹ åˆ°ç”¨æˆ·çš„å…´è¶£åå¥½ï¼Œæ˜¯æ¨èç³»ç»Ÿä¸­çš„ä¸€å¤§æŒ‘æˆ˜ã€‚è¿™ç¯‡æ–‡ç« ä»‹ç»ä¸€ç§åœ¨çº¿å­¦ä¹ çš„ï¼ŒåŸºäºèšç±»çš„å¤šè‡‚è€è™æœºæ–¹æ³•ã€‚å®ƒåŸºäºç”¨æˆ·ä¸€èˆ¬å¯ä»¥è¢«åˆ’åˆ†æˆä¸€äº›äººç¾¤èšç±»ï¼ˆè¿™äº›èšç±»å…·æœ‰ç±»ä¼¼çš„åå¥½ï¼‰çš„ç°å®å‡è®¾ï¼Œå®ƒåŠ é€Ÿäº†ç”¨æˆ·çš„åå¥½å­¦ä¹ ï¼Œå› ä¸ºå®ƒæŠŠä»»åŠ¡è½¬åŒ–æˆäº†èšç±»å³åˆ¤æ–­ç”¨æˆ·å±äºå“ªä¸ªèšç±»ï¼Œå¹¶ä¸”ä¸€èˆ¬æ¥è¯´ï¼Œä»…ä»…åªæœ‰å°‘æ•°å‡ ä¸ªäººç¾¤èšç±»ï¼ˆç›¸å¯¹æ¨èç³»ç»Ÿè¦æ’åºçš„itemçš„æ•°é‡ï¼‰ã€‚å°½ç®¡å¦‚æ­¤ ä»…ä»…é å®ƒè‡ªå·±çš„èšç±»æ˜¯ä¸å¤Ÿçš„ã€‚ èšç±»å†…éƒ¨ç”¨æˆ·çš„å¤šæ ·æ€§å¯ä»¥è¢«å½“ä½œç”¨æˆ·æ’åºæ—¶å‚æ‚çš„å™ªå£°ï¼Œå…·æœ‰å†³å®šæ€§çš„æ–¹æ³•æ¯”å¦‚å†³ç­–æ ‘ä¸€èˆ¬åœ¨å­˜åœ¨è¿™ç§å™ªå£°æ—¶å¾€å¾€è¡¨ç°ä¸å¥½ã€‚

å°½ç®¡åœ¨æœ‰æ’åºå¹²æ‰°å™ªå£°çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å‘ç°æ‰€è°“çš„åŒºåˆ†é¡¹å¯¹äºåˆ¤æ–­ç”¨æˆ·å±äºå“ªä¸ªèšç±»å…·æœ‰ååˆ†å¼ºçš„æŒ‡å‘æ€§ã€‚ ç”¨è¿™äº›åŒºåˆ†é¡¹ï¼ŒåŸºäºèšç±»çš„å¤šè‡‚è€è™æœºç®—æ³•å¯ä»¥ååˆ†æœ‰æ•ˆçš„åˆ©ç”¨ç”¨æˆ·çš„åé¦ˆï¼Œå¿«é€Ÿçš„å­¦ä¹ åˆ°ç”¨æˆ·åˆ°åº•å±äºå“ªä¸€ä¸ªèšç±»ã€‚



In this paper we revisit the cold-start task for new users of a recommender system, which remains a core challenge. When a new user joins the system it initially has no knowledge of the preferences of the user and so would like to quickly learn these1. The recommender system therefore initially starts in an â€œexplorationâ€ phase where the first few items that it asks the new user to rate are chosen with the aim of discovering the userâ€™s preferences. For brevity we focus on the simplest setup where a user explicitly rates items presented to them, e.g. on a 1-5 scale or binary like/dislike feedback,
and the aim of the recommender system is to predict other items that the user may like.

æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å›é¡¾äº†åœ¨æ¨èç³»ç»Ÿä¸­å¯¹äºæ–°ç”¨æˆ·çš„å†·å¯åŠ¨ä»»åŠ¡ï¼Œ æ˜¯ä¸€ä¸ªæ ¸å¿ƒçš„æŒ‘æˆ˜ã€‚å½“æ–°ç”¨æˆ·åŠ å…¥ï¼Œåˆå§‹æ—¶æ¨èç³»ç»Ÿä¸çŸ¥é“ä»–çš„å…´è¶£åå¥½ï¼Œæ‰€ä»¥å®ƒå¿…é¡»å¿«é€Ÿå­¦ä¹ ã€‚å› æ­¤æœ€å¼€å§‹æ˜¯ä¸€ä¸ªæ¢ç´¢é˜¶æ®µï¼Œåœ¨è¿™ä¸ªé˜¶æ®µï¼Œå¸¦ç€å­¦ä¹ ç”¨æˆ·åå¥½çš„ç›®çš„ä¼šæ¨é€å°‘é‡çš„å†…å®¹ç»™æ–°ç”¨æˆ·è®©ä»–å»æ‰“åˆ†ã€‚ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬åˆ©ç”¨ç”¨æˆ·æ˜¾å¼æ‰“åˆ†åšä¸ºä¸€ä¸ªç®€å•çš„æ–¹æ³•ï¼Œæ¯”å¦‚1-5åˆ†ï¼Œæˆ–è€…å–œæ¬¢æˆ–è€…ä¸å–œæ¬¢ã€‚



One common approach to this new user cold-start task is to take ratings already collected from a population of users, use these to cluster users into groups and then train a decision-tree to learn a mapping from item ratings to the user group, see for example Figure 1(a). When a new user joins the system this decision-tree is used to decide which items the user is initially asked to rate and in this way the group to which the user belongs is initially estimated. Once the group is estimated, the system recommends items liked by members of that group e.g. using matrix factorisation or another
collaborative filtering approach.

ä¸€ä¸ªå¸¸è§çš„æ–¹æ³•ï¼Œæ˜¯åˆ©ç”¨ä¸€å®šé‡ç”¨æˆ·æ‰“åˆ†ï¼Œç”¨è¿™äº›å»èšç±»äººç¾¤ï¼Œç„¶åè®­ç»ƒä¸€ä¸ªå†³ç­–æ ‘æ ¹æ®æ–°ç”¨æˆ·çš„æ‰“åˆ†æ¥æŠŠç”¨æˆ·åˆ†ç¾¤ï¼Œå¦‚å›¾1(a)ã€‚ å½“æ–°ç”¨æˆ·æ¥çš„æ—¶å€™ï¼Œå†³ç­–æ ‘è¢«ç”¨æ¥å†³å®šç»™ç”¨æˆ·å“ªäº›å†…å®¹å»æ‰“åˆ†ï¼Œ é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç”¨æˆ·å±äºå“ªä¸ªäººç¾¤å°±è¢«ä¼°è®¡å‡ºæ¥äº†ã€‚ä¸€æ—¦äººç¾¤è¢«ä¼°è®¡å‡ºæ¥ï¼Œç³»ç»Ÿå°±ä¼šæ¨èè¿™ä¸ªäººç¾¤å–œæ¬¢çš„å†…å®¹ï¼Œ é‡‡ç”¨çš„æ–¹æ³•æœ‰çŸ©é˜µåˆ†è§£ï¼Œæˆ–è€…å†™ååŒè¿‡æ»¤æ–¹æ³•ã€‚



However, typically users clustered in the same group do not give identical ratings to an item. Rather there is a spread of ratings, and
this intra-cluster variability between users can be thought of as adding noise to the ratings. Unfortunately, decision trees can easily make mistakes in the face of such noise. For example, Figure1(b) shows the measured decision-tree accuracy for Netflix data clustered into 16 groups (see later for more details). It can be seen that the accuracy is as low as 50-60% for a number of groups

å°½ç®¡å¦‚æ­¤ï¼Œä¸€ä¸ªäººç¾¤ä¸­çš„å…¸å‹ç”¨æˆ·å¹¶ä¸ä¸€å®šç»™å‡ºç›¸åŒçš„æ‰“åˆ†å¯¹äºåŒä¸€ä¸ªå†…å®¹ï¼Œ ç›¸åä¼šå­˜åœ¨ä¸åŒçš„è¯„åˆ†ï¼Œå¹¶ä¸”è¿™ç§äººç¾¤å†…éƒ¨çš„ç”¨æˆ·ä¹‹é—´çš„å¤šæ ·æ€§è¢«è®¤ä¸ºç»™è¯„åˆ†å¢åŠ äº†å¹²æ‰°ã€‚ä¸å¹¸çš„çš„æ˜¯ï¼Œå†³ç­–æ ‘å¾ˆå®¹æ˜“åœ¨è¿™ç§æƒ…å†µä¸‹çŠ¯é”™ã€‚æ¯”å¦‚å›¾1(b) æ‰€ç¤ºï¼Œå†³ç­–æ ‘åŸºäºå¥ˆé£æ•°æ®16åˆ†ç±»çš„ç²¾åº¦ï¼Œå¯ä»¥çœ‹å‡ºæœ‰äº›åˆ†ç±»çš„ç²¾åº¦ä»…ä»…åœ¨50-60%ã€‚



Multi-arm bandits (MABs), and more generally online convex learning, has been the subject of much interest in recent years.
However, naive application of standard bandit algorithms to the cold-start task leads to poor performance. If we think of each recommender
system item as an arm of a MAB then we run into the difficulty that (i) there are many arms and so learning is slow and (ii) repeated pulls of the same arm tend to be highly correlated 2. One remedy is to associate an arm with each group rather than each item. For each group the available items are sorted in descending order of their predicted rating by users in that group. Pulling the arm for a group then corresponds to asking the user to rate
the next item from this sorted list, i.e. the unrated item predicted to have the highest rating for members of the group. While this greatly reduces the number of arms in the MAB, as we will see later the learning rate remains very slow. This is because items rated highly by members of one group tend to also be rated highly by members of at least some of the other groups, and so the user ratings for these items do not serve to strongly distinguish between groups and so allow rapid learning.

å¤šè‡‚è€è™æœºå’Œæ›´é€šç”¨çš„åœ¨çº¿å‡¸ä¼˜åŒ–ï¼Œ æ˜¯è¿‘äº›å¹´æ¥çš„ç ”ç©¶çƒ­ç‚¹ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ ‡å‡†è€è™æœºç®—æ³•å¾—çš„ç®€å•åº”ç”¨å¯¹äºå†·å¯åŠ¨é—®é¢˜æ¥è¯´æ•ˆæœä¸å¥½ã€‚å‡è®¾æˆ‘ä»¬æŠŠæ¯ä¸ªæ¨èé¡¹è€ƒè™‘æˆä¸€ä¸ªè€è™æœºçš„ä¸€ä¸ªè‡‚ï¼Œæˆ‘ä»¬é¢ä¸´2ä¸ªé—®é¢˜ï¼š ï¼ˆ1ï¼‰æœ‰å¤ªå¤šè‡‚äº†ï¼Œä½¿å¾—å­¦ä¹ çš„éå¸¸æ…¢ ï¼ˆ2ï¼‰é‡å¤æ‹‰ç›¸åŒè‡‚ä¼šå¯¼è‡´é«˜ç›¸å…³æ€§ã€‚ 

ä¸€ä¸ªè¡¥æ•‘æ–¹æ³•æ˜¯å…³è”ä¸€ä¸ªè‡‚åˆ°ä¸€ä¸ªäººç¾¤ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ¨èé¡¹ã€‚å¯¹äºæ¯ä¸ªäººç¾¤ï¼Œæ‰€æœ‰çš„å¯é€‰æ¨èé¡¹è¢«æŒ‰ç…§ä»–ä»¬åœ¨è¿™ä¸ªäººç¾¤ä¸­çš„é¢„æµ‹æ‰“åˆ†å€’æ’ã€‚ æ‹‰å¯¹åº”äººç¾¤çš„è‡‚å¯¹åº”ç€è®©è¿™ä¸ªç”¨æˆ·å¯¹å€’æ’ä¸Šçš„æ¨èé¡¹è¿›è¡Œæ‰“åˆ†ï¼Œæ²¡æœ‰è¢«æ‰“è¿‡åˆ†çš„æ¨èé¡¹åœ¨è¢«é¢„æµ‹ä¸ºè¯¥äººç¾¤çš„æœ€é«˜åˆ†ã€‚åŒæ—¶å½“è€è™æœºçš„è‡‚å¤§å¤§å‡å°‘ä»¥åæˆ‘ä»¬ä»ä¼šå‘ç°ï¼Œå­¦ä¹ çš„é€Ÿåº¦è¿˜æ˜¯éå¸¸æ…¢ã€‚ è¿™ä¸ªæ˜¯å› ä¸ºï¼Œé‚£äº›æ€»æ˜¯è¢«ä¸€ä¸ªäººç¾¤è¯„é«˜åˆ†çš„æ¨èé¡¹ä¹Ÿæ€»æ˜¯å®¹æ˜“è¢«å¦å¤–å‡ ä¸ªäººç¾¤è¯„é«˜åˆ†ï¼Œ æ‰€ä»¥ç”¨æˆ·çš„è¿™äº›è¯„åˆ†ä¸ä¼šå¸¦æ¥ä¸åŒäººç¾¤ä¹‹é—´çš„åŒºåˆ†æ€§ä»¥åŠå¿«é€Ÿå­¦ä¹ æ•ˆæœã€‚



In this paper we propose a novel cluster-based bandit algorithm that achieves fast learning in cold-start, e.g. for the standard Netflix
dataset < 10 items need to be rated in order to reliably distinguish between 16 user groups and < 12 items to reliably distinguish between
32 groups. We show that the group of a user is identified with significantly higher accuracy than with a decision-tree without
incurring higher regret i.e the learning performance is fundamentally superior to that of a decision-tree.

è¿™ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„åŸºäºèšç±»çš„å¤šè‡‚è€è™æœºç®—æ³•ï¼Œå®ç°äº†å†·å¯åŠ¨åœºæ™¯çš„å¿«é€Ÿå­¦ä¹ ã€‚æ¯”å¦‚ï¼Œå¯¹äºæ ‡å‡†çš„å¥ˆé£æ•°æ®é›†ï¼Œä¸ºäº†æœ‰æ•ˆæ„å»º16ä¸ªäººç¾¤çš„åŒºåˆ†æ€§ï¼Œå°‘äº10ä¸ªæ¨èé¡¹éœ€è¦è¢«è¯„åˆ†ã€‚ä¸ºäº†æœ‰æ•ˆæ„å»º32ä¸ªäººç¾¤çš„åŒºåˆ†æ€§ï¼Œè‡³å°‘12ä¸ªæ¨èé¡¹éœ€è¦è¢«è¯„åˆ†ã€‚æˆ‘ä»¬å±•å‡ºå‡ºæ¥çš„ï¼Œç”¨æˆ·åœ¨è¢«å½’ç±»æ—¶çš„å‡†ç¡®æ€§æ˜¾è‘—é«˜äºå†³ç­–æ ‘ï¼Œå¹¶ä¸”æ²¡æœ‰å¯¼è‡´ä»»ä½•å…¶ä»–å‰¯ä½œç”¨ï¼Œä¹Ÿå°±æ˜¯å®ƒçš„å­¦æ ¡è¡¨ç°å½»åº•ç”±äºå†³ç­–æ ‘ã€‚



For a recent survey of solutions to the cold-start see [4, 5]. Passive approaches include recommending popular items, use of item based
recommendation (once user starts rating items an item-based approach is used to recommend similar items), transfer learning
from another recommender system previously used by a user, and asking new users to rate a fixed list of items. Examples of early
work on active learning include IGCN (information gain through clustered neighbors) which uses a decision tree with user clusters
as leaves [8] and the ternary decision-tree approach of [7]. More recently, [1] uses representative items i.e. after completing
the ratings matrix ğ‘…, ğ‘˜ columns of ğ‘… are selected, the ratings of the other items are represented as a linear combination of these and
during cold start a new user is asked to rate these representative items. This approach is extended to use a decision-tree approach
by [9]. In [10] a matrix factorization approach is proposed whereby a decision-tree is trained to map from item ratings to the latent feature
vector for a user. Use of multi-arm bandits for cold-start has also received attention. In [6] after completing the ratings matrix ğ‘… its rows are clustered and the average ratings vector for each cluster is used as a representative user. During cold start an MAB is used to select the average ratings vector to use and the user is asked to rate next highest item in the vector â€“ this is akin to the cluster-bandit algorithm with no exploration phase. In [2] a MAB
is used to select between recommender strategies, typically recommending popular items initially for a new user and later switching to a kNN or matrix factorisation model.

å¼•ç”¨4,5 æ˜¯ä¸€äº›è§‚å½±å†·å¯åŠ¨é—®é¢˜çš„è°ƒç ”ã€‚ä¸€äº›æ¯”è¾ƒæœ‰æ•ˆçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬æ¨é€çƒ­é—¨å†…å®¹ï¼ŒåŸºäºå†…å®¹ç›¸å…³æ€§çš„æ¨èï¼Œ è¿ç§»ä»å¦å¤–ä¸€ä¸ªæ¨èç³»ç»Ÿä¸­å­¦ä¹ çš„æ¨¡å‹ï¼Œä»¥åŠç›´æ¥è¯¢é—®æ–°ç”¨æˆ·ï¼ˆç»™ä»–ä»¬æä¾›ä¸€äº›å›ºå®šé€‰é¡¹ï¼‰ã€‚ä¸€äº›æ›´æ—©çš„å·¥ä½œï¼Œæ¯”å¦‚ä¸»åŠ¨å­¦ä¹ åŒ…æ‹¬IGCNï¼ˆinformation gain through clustered neighborsï¼‰ï¼Œè¿™ç§æ–¹æ³•ä½¿ç”¨äº†ä¸€ä¸ªå†³ç­–æ ‘å’Œä¸‰å…ƒå†³ç­–æ ‘æ–¹æ³•ã€‚ æ›´è¿‘æœŸçš„ä¸€äº›ç ”ç©¶ï¼Œä½¿ç”¨è¡¨ç¤ºå­¦ä¹ ï¼Œåœ¨å®Œæˆäº†è¯„åˆ†çŸ©é˜µRä»¥åï¼Œå…¶ä¸­Kåˆ—è¢«é€‰æ‹©ï¼Œå…¶ä»–åˆ—çš„è¯„åˆ†è¢«è¡¨è¾¾ä¸ºè¿™Kåˆ—çš„çº¿æ€§ç»„åˆå¹¶ä¸”åœ¨å†·å¯åŠ¨é˜¶æ®µï¼Œä¼šè®©æ–°ç”¨æˆ·ä¸æ–­å¯¹è¿™äº›å†…å®¹è¿›è¡Œè¯„åˆ†ã€‚è¿™ç§æ–¹æ³•æ‰©å±•äº†ä½¿ç”¨å†³ç­–æ ‘æ–¹æ³• By [9].  æ–‡ç« [10] ä¸­ï¼Œæå‡ºäº†ä¸€ä¸ªçŸ©é˜µåˆ†è§£çš„æ–¹æ³•ï¼Œé€šè¿‡ä¸€ä¸ªå†³ç­–æ ‘æ¥æ˜ å°„å†…å®¹è¯„åˆ†åˆ°ä¸€ä¸ªéšå¼ç‰¹å¾å‘é‡ç»™ç”¨æˆ·ã€‚ ä½¿ç”¨å¤šè‡‚è€è™æœºç®—æ³•åœ¨å†·å¯åŠ¨é¢†åŸŸï¼Œä¹Ÿå¼•èµ·äº†æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ–‡ç« [6]ä¸­ï¼Œåœ¨å®Œæˆè¯„åˆ†çŸ©é˜µRåï¼ŒæŒ‰è¡Œè¢«èšç±»ï¼Œè¡Œçš„æ‰“åˆ†å‡å€¼ä¸ºè®¤åšæ¯ä¸€ä¸ªèšç±»ä¸­çš„å…¸å‹ç”¨æˆ·ã€‚åœ¨å†·å¯åŠ¨é˜¶æ®µï¼ŒMABè¢«ç”¨æ¥æå–å‡åˆ†æ‰“åˆ†å‘é‡ï¼Œè®©ç”¨æˆ·å¯¹æœ€æœ‰å¯èƒ½çš„å†…å®¹è¿›è¡Œæ‰“åˆ† - è¿™ç§æ–¹æ³•æ¥è¿‘äºæ²¡æœ‰æ¢æµ‹é˜¶æ®µçš„å¤šè‡‚è€è™æœºã€‚

æ–‡ç« [2] ä¸­ï¼Œ MABè¢«ç”¨æ¥é€‰æ‹©æ¨èç­–ç•¥ï¼Œæ¯”å¦‚æ˜¯çƒ­é—¨æ¨èç»™æ–°ç”¨æˆ·ï¼Œè¿˜æ˜¯åˆ‡æ¢åˆ°KNNå’ŒçŸ©é˜µåˆ†è§£æ¨¡å‹ã€‚



3 CLUSTER-BASED BANDIT ALGORITHM
We have a set ğº of user groups. Each user belongs to one group ğ‘” âˆˆ ğº. We also have a set of items ğ‘‰ . Given a new user our task is
to quickly learn which group they belong to by asking the user to rate items in ğ‘‰ , using the fact that the distribution of item ratings
varies depending on the userâ€™s group.

å‡è®¾ï¼Œæˆ‘ä»¬æœ‰ä¸ªäººç¾¤é›†åˆGï¼Œ æ‰€æœ‰äººå±äºå…¶ä¸­äººç¾¤gã€‚ æˆ‘ä»¬æœ‰ä¸€ä¸ªå†…å®¹é›†åˆVã€‚ å½“æ–°ç”¨æˆ·æ¥çš„æ—¶å€™ï¼Œæˆ‘ä»¬çš„ä»»åŠ¡æ˜¯é€šè¿‡ç”¨æˆ·çš„æ‰“åˆ†è¡Œä¸ºå¿«é€Ÿå­¦ä¹ è¿™ä¸ªç”¨æˆ·å±äºé‚£ä¸ªäººç¾¤ã€‚å‰æäº‹å®æ¡ä»¶æ˜¯ï¼Œä¸åŒçš„äººç¾¤ï¼Œä»–ä»¬åœ¨å†…å®¹ä¸Šçš„è¯„åˆ†å…·æœ‰åŒºåˆ†æ€§ã€‚



3.1 Group Indicator Vector
What we would like to measure is an indicator vector ğ¼ i.e. a vector for which as we collect more user ratings the element ğ¼ (ğ‘”) tends
towards 1 when a new user belongs to group ğ‘” and all other elements ğ¼ (â„), â„ â‰  ğ‘” tend towards 0. We can obtain such a vector as follows. Start by definingï¼š

æˆ‘ä»¬æƒ³è¦è®¡ç®—çš„æ˜¯ä¸€ä¸ª0-1å‘é‡ $I(g)$ï¼Œæ‰€æœ‰å±äºgäººç¾¤çš„è§‚å½±è¯„åˆ†è¶‹è¿‘äº1ï¼Œ åŒæ—¶å…¶ä»–äººç¾¤hçš„è§‚å½±å†…å®¹åˆ™è¶‹è¿‘äº0ã€‚é€šè¿‡å¦‚ä¸‹å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°è¿™æ ·çš„ä¸€ä¸ªå‘é‡ï¼š

$$ \displaystyle R_n(g,h) = \sum_{i=1}^{n}\alpha_{i}^{n}(g,h) \frac{r(v_i) - \mu(h,v_i)}{\mu(g, v_i) - \mu(h,v_i)}$$,

å…¶ä¸­$v_i$  æ˜¯ç”¨æˆ·è¯„åˆ†è¿‡æ¨èåºåˆ—çš„ç¬¬ié¡¹ï¼Œ $r(v_i)$ æ˜¯å…¶è¯„åˆ†ï¼Œ$\mu(g,v_i)$ æ˜¯äººç¾¤gä¸­æ‰€æœ‰äººå¯¹$v_i$çš„è¯„åˆ†å‡å€¼ï¼Œ$\alpha_{i}^{n}(g,h)$ æ˜¯æƒé‡ï¼Œå…¶ä¸­$\displaystyle\sum_ {i=1}^{n}\alpha_{i}^{n}(g,h) =1$

$\mu(g,v_i)$ çš„ä¼°è®¡å€¼æ˜¯å¯çŸ¥çš„ï¼Œæ¯”å¦‚ä»ç°å­˜çš„ç”¨æˆ·ä¸­çš„è¯„åˆ†å¾—åˆ°ã€‚æ³¨æ„ï¼Œ$R_n(g,h)$ çš„è®¡ç®—ä»…è¦æ±‚ç”¨æˆ·å¯¹æ¯ä¸ªå†…å®¹è¯„åˆ†ä¸€æ¬¡ï¼Œå½“ç„¶äº†å¦‚æœå­˜åœ¨ç”¨æˆ·é‡å¤è¯„åˆ†$v_i$åºåˆ—ä¼šå­˜åœ¨é‡å¤å€¼ã€‚



To streamline notation suppose the new user is in group 1, we can always relabel the groups so that this holds3.  Then . 

$$ \displaystyle R_n(1,h) = \sum_{i=1}^{n}\alpha_{i}^{n}(1,h) \frac{r(v_i) - \mu(h,v_i)}{\mu(1, v_i) - \mu(h,v_i)}$$,

Intuitively, the deviations ğ‘Ÿ (ğ‘£ğ‘– ) âˆ’ ğœ‡(1, ğ‘£), ğ‘– = 1, . . . , ğ‘› tend to fluctuate around 0, as otherwise there would be a consistent offset between the userâ€™s
ratings and the group ratings in which case the user would better be assigned to a different group. Therefore ğ‘…ğ‘› (1, â„) â†’ 1 as ğ‘› â†’ âˆ for â„ â‰  1. By the same argument, ğ‘…ğ‘› (ğ‘”, 1) â†’ 0 as ğ‘› â†’ âˆfor ğ‘” â‰  1. Hence,

$$I(g) = \underset{h\;\in G\;\backslash\;\{g\}}{min}R_n(g,h)$$

is an indicator vector of the desired form i.e. ğ¼ (1) â†’ 1 and ğ¼ (ğ‘”) â†’0, ğ‘” â‰  1 as ğ‘› â†’ âˆ. We then estimate the group $\hat{g}$ that the new user
belongs to using

$$\hat{g} \in \underset{h\;\in G\;\backslash\;\{g\}}{argmax} I(g) $$   

The key to fast learning is that ğ¼ (ğ‘”) converges quickly to a (0, 1) vector.

ä¸ºäº†ç†è§£å…¬å¼ï¼Œå‡è®¾æ–°ç”¨æˆ·å±äºGroup1ã€‚ æœ‰å¦‚ä¸‹å…¬å¼ï¼š

$$ \displaystyle R_n(1,h) = \sum_{i=1}^{n}\alpha_{i}^{n}(1,h) \frac{r(v_i) - \mu(h,v_i)}{\mu(1, v_i) - \mu(h,v_i)}$$,

ç›´è§‚çš„è¯´ï¼Œğ‘Ÿ (ğ‘£ğ‘– ) âˆ’ ğœ‡(1, ğ‘£)çš„å·®ï¼Œåº”è¯¥åœ¨è¶‹è¿‘äºåœ¨0é™„è¿‘æ³¢åŠ¨ï¼Œä¹Ÿå°±æ˜¯ç”¨æˆ·æ‰“åˆ†å’Œæ‰€å±äººç¾¤çš„å¹³å‡æ‰“åˆ†åº”è¯¥è¶‹å‘ä¸€è‡´ã€‚å› æ­¤$R_n(1,h)$è¶‹å‘äº1ï¼Œä¸”$R_n(g,1), g \neq 1 $ è¶‹å‘äº0ã€‚

ç”¨$$\hat{g} \in \underset{h\;\in G\;\backslash\;\{g\}}{argmax} I(g) $$    è¿™ä¸ªå…¬å¼æ¥ä¼°è®¡æ–°ç”¨æˆ·å±äºå“ªä¸ªgroupã€‚å¿«é€Ÿå­¦ä¹ çš„å…³é”®å°±åœ¨äºå¦‚ä½•è®©$I(g)$ å¿«é€Ÿå˜æˆä¸€ä¸ªa(0,1) çš„å‘é‡



Intuitively, an item ğ‘£ helps to distinguish whether a user belongs to group ğ‘” rather than group â„ when (i) the mean rating of ğ‘£ by
users in group ğ‘” is very different from that of users in group â„ i.e. (ğœ‡(ğ‘”, ğ‘£) âˆ’ ğœ‡(â„, ğ‘£))2 is large, and (ii) when the ratings tend to
be consistent/reliable i.e. the variance ğœ2(ğ‘”, ğ‘£) is small. That is, we expect that

ç›´è§‚çš„çœ‹ï¼Œç”¨æˆ·ä¸€ä¸ªè§‚å½±å†…å®¹çš„è¯„åˆ†æ¥è¿‘äººç¾¤gï¼Œè€Œä¸”éå¸¸å¼‚äºäººç¾¤hå¯ä»¥å¸®åŠ©åˆ¤æ–­ä»–å±äºäººç¾¤g

